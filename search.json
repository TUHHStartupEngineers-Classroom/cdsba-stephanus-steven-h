[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "1 Read data\n\nrandom_vars &lt;- readRDS(\"E:/Master Study/TUHH/Wise 23-24/Causal Data Science for Business Analytics/Causal_Data_Science_Data/random_vars.rds\")\n\nrandom_vars\n\n\n\n  \n\n\n\n\n\n2 Mean, variance and standard deviation of age & income\n\n## Calculation\nexpected_age &lt;- mean(random_vars$age)\nexpected_income &lt;- mean(random_vars$income)\nvariance_age &lt;- var(random_vars$age)\nvariance_income &lt;- var(random_vars$income)\nsd_age &lt;- sd(random_vars$age)\nsd_income &lt;- sd(random_vars$income)\n\n\n## Print result\ncat(\"Mean age :\", expected_age, \"\\n\")\nMean age : 33.471\ncat(\"Mean income :\", expected_income, \"\\n\")\nMean income : 3510.731\ncat(\"Variance of age:\", variance_age, \"\\n\")\nVariance of age: 340.6078\ncat(\"Variance of income:\", variance_income, \"\\n\")\nVariance of income: 8625646\ncat(\"Standard deviation of age:\", sd_age, \"\\n\")\nStandard deviation of age: 18.45556\ncat(\"Standard deviation of income:\", sd_income, \"\\n\")\nStandard deviation of income: 2936.945\n\n\n\n3 Explain, if it makes sense to compare the standard deviations.\n\nprint(\"Both standard deviations are used to see how wide the gaps for both age and income level. \n      However, a sense of knowledge when comparing two standard deviations is a must, for example in this case, age is usually between 0-150 of human life span,\n      while income could be thousands, hundred thousand or millions depending of the currency used.\")\n[1] “Both standard deviations are used to see how wide the gaps for both age and income level. However, a sense of knowledge when comparing two standard deviations is a must, for example in this case, age is usually between 0-150 of human life span,while income could be thousands, hundred thousand or millions depending of the currency used.”\n\n\n\n4 Then, examine the relationship between both variables and compute\n\n## Calculation\ncovariance &lt;- cov(random_vars$age, random_vars$income)\ncorrelation &lt;- cor(random_vars$age, random_vars$income)\n\n## Print Result\ncat(\"Covariance :\", covariance, \"\\n\")\nCovariance : 29700.15\ncat(\"Correlation :\", correlation, \"\\n\")\nCorrelation : 0.5479432\n\n\n# What measure is easier to interpret? Please discuss your interpretation.\nprint(\"Correlation is much easier to interpret and intuitive since it spans between -1 and +1, so it is more convenient to see the relationship between parameters even when it has different unit and wide range of numbers\")\n[1] “Correlation is much easier to interpret and intuitive since it spans between -1 and +1, so it is more convenient to see the relationship between parameters even when it has different unit and wide range of numbers”\n\n\n\n5 Compute the conditional expected value for\n\n## Calculation\nmean_age_under_18 &lt;- mean(random_vars$age[random_vars$age &lt;= 18])\nmean_age_between_1865 &lt;- mean(random_vars$age[random_vars$age &gt;= 18 & random_vars$age &lt;= 65])\nmean_age_above_65 &lt;- mean(random_vars$age[random_vars$age &gt;= 65])\n\n## Print the result\ncat(\"Mean income for age &lt;= 18:\", mean_age_under_18, \"\\n\")\nMean income for age &lt;= 18: 11.42975\ncat(\"Mean income for 18&lt;age&lt;65:\", mean_age_between_1865, \"\\n\")\nMean income for 18&lt;age&lt;65: 37.30544\ncat(\"Mean income for age &gt;= 65:\", mean_age_above_65, \"\\n\")\nMean income for age &gt;= 65: 74.15254"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "library(tidyverse) library(rdd) library(estimatr)"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subsclassifications",
    "section": "",
    "text": "library(Matching) library(ggplot2) library(MatchIt) library(dplyr) library(MASS) library(dagitty)"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "#| output: asis npm install -g yaml-lint # Load required libraries library(ggplot2) library(dplyr) library(tidyverse)\n\n1 Load the data\ncustomer_sat &lt;- readRDS(“E:/Master Study/TUHH/Wise 23-24/Causal Data Science for Business Analytics/Causal_Data_Science_Data/customer_sat.rds”)\ncustomer_sat\n\n\n2 Step 1: Regress satisfaction on follow_ups\nmodel1 &lt;- lm(satisfaction ~ follow_ups, data = customer_sat) summary(model1)\n\n\n3 Step 2: Regress satisfaction on follow_ups and account for subscription\nmodel2 &lt;- lm(satisfaction ~ follow_ups + subscription, data = customer_sat) summary(model2)\n\n\n4 Compare coefficients\ncoef_comparison &lt;- data.frame( FollowUps_Only = coef(model1)[2], FollowUps_Subscription = coef(model2)[2], Subscription_Premium = coef(model2)[3], Subscription_Elite = coef(model2)[4] ) print(coef_comparison)\n\n\n5 Plot the data\nggplot(customer_sat, aes(x = follow_ups, y = satisfaction, color = subscription)) + geom_point() + geom_smooth(method = “lm”, se = FALSE) + labs(title = “Relationship between Follow-up Calls and Satisfaction”, x = “Follow-up Calls”, y = “Satisfaction”, color = “Subscription Level”)"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "1 Load required libraries\nlibrary(ggplot2) library(dplyr)\n\n\n2 Load the data\nabtest_online &lt;- readRDS(“E:/Master Study/TUHH/Wise 23-24/Causal Data Science for Business Analytics/Causal_Data_Science_Data/abtest_online.rds”)\n\n\n3 Step 1: Check covariate balance across groups and plot\ncovariate_balance_plot &lt;- ggplot(abtest_online, aes(x = purchase_amount, color = as.factor(chatbot))) + geom_density() + labs(title = “Covariate Balance Check”, x = “Purchase Amount”, color = “Chatbot Group”)\nprint(covariate_balance_plot)\n\n\n4 Step 2: Run regression to find the effect of chatbot on sales\nsales_regression &lt;- lm(purchase_amount ~ chatbot + mobile_device + previous_visit, data = abtest_online) summary(sales_regression)\n\n\n5 Step 3: Find subgroup-specific effects with interaction (exemplary group: mobile users)\ninteraction_model &lt;- lm(purchase_amount ~ chatbot * mobile_device + previous_visit, data = abtest_online) summary(interaction_model)\n\n\n6 Step 4: Logistic regression for binary outcome (purchase)\nlogistic_regression &lt;- glm(purchase ~ chatbot + mobile_device + previous_visit, data = abtest_online, family = “binomial”) summary(logistic_regression)"
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "1 Load required libraries\nlibrary(dplyr) library(tidyverse)\n\n\n2 Load the data\nhospdd &lt;- readRDS(“E:/Master Study/TUHH/Wise 23-24/Causal Data Science for Business Analytics/Causal_Data_Science_Data/hospdd.rds”)\nhead(hospdd)\n\n\n3 Use filter() to subset the data and mean() to calculate the mean of the subset\nmean_satis_newpcd &lt;- hospdd %&gt;% filter(procedure == 1) %&gt;% summarise(mean_value = mean(satis))\nmean_satis_oldpcd &lt;- hospdd %&gt;% filter(procedure == 0) %&gt;% summarise(mean_value = mean(satis))\n\n\n4 Compare the result\nprint(“Mean of Hospital Satisfaction where new procedure is applied:”) print(mean_satis_newpcd) print(“Mean of Hospital Satisfaction where new procedure is NOT applied”) print(mean_satis_oldpcd)\n\n\n5 Convert time variables to factors\nhospdd\\(month &lt;- as.factor(hospdd\\)month) hospdd\\(hospital &lt;- as.factor(hospdd\\)hospital)\n\n\n6 Perform difference-in-differences analysis using linear regression\n\n\n7 Include group and time fixed effects\n\n\n8 Option 1: Include as.factor(month) + as.factor(hospital)\nmodel1 &lt;- lm(satis ~ frequency * month + as.factor(month) + as.factor(hospital), data = hospdd)\n\n\n9 Option 2: Include month + hospital\nmodel2 &lt;- lm(satis ~ frequency * month + month + hospital, data = hospdd)\n\n\n10 Display the regression results\nprint(“Linear Regression Results (Option 1):”) summary(model1)\nprint(“Linear Regression Results (Option 2):”) summary(model2)"
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probablity Theory",
    "section": "",
    "text": "1 Assignment 1 - Probability Tree\nPrint the result\n\n## Print the results\ncat(\"P(T ∩ S):\", P_T_and_S, \"\\n\")\nP(T ∩ S): 0.06\ncat(\"P(T ∩ ~S):\", P_T_and_not_S, \"\\n\")\nP(T ∩ ~S): 0.42\ncat(\"P(~T ∩ S):\", P_not_T_and_S, \"\\n\")\nP(~T ∩ S): 0.24\ncat(\"P(~T ∩ ~S):\", P_not_T_and_not_S, \"\\n\")\nP(~T ∩ ~S): 0.28\ncat(\"Sum of all four probabilities:\", sum_of_probabilities, \"\\n\")\nSum of all four probabilities: 1\n\n\n\n2 Assignment 2 - Set Theory\n\n# Print the results\ncat(\"Percentage of customers using all three devices:\", percentage_all_three_devices, \"%\\n\")\nPercentage of customers using all three devices: 0.5 %\ncat(\"Percentage of customers using at least two devices:\", percentage_at_least_two_devices, \"%\\n\")\nPercentage of customers using at least two devices: 19.4 %\ncat(\"Percentage of customers using only one device:\", percentage_only_one_device, \"%\\n\")\nPercentage of customers using only one device: 80.1 %\n\n\n\n3 Assignment 3 - Bayesian Theorem\n\n# Print the results\ncat(\"a. P(~Faulty_prod | Alarm):\", P_not_Faulty_prod_given_Alarm, \"\\n\")\n\nP(~Faulty_prod | Alarm): 0.1983471\n\ncat(\"b. P(Faulty_prod | Alarm):\", P_Faulty_prod_given_Alarm, \"\\n\")\n\nP(Faulty_prod | Alarm): 0.8016529\n\n\n\ncat(\"These results show that in case the alarm is triggered, there is a possibility of about\", \n    percentage_not_Faulty_prod_given_Alarm, \"% that the product is flawless and a probability of\", \n    percentage_Faulty_prod_given_Alarm, \"% that the product is faulty.\", \"\\n\")\nThese results show that in case the alarm is triggered, there is a possibility of about 19.83 % that the product is flawless and a probability of 80.17 % that the product is faulty."
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "6.1 Header 2",
    "text": "6.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "library(dplyr) library(tidyverse)"
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "1 Install and load required packages\nlibrary(tidyverse) library(rddtools) library(rddensity) library(ggthemes) library(scales) library(ggplot2) library(tidyverse)\n\n\n2 Load all data\ncoupon_data &lt;- readRDS(‘E:/Master Study/TUHH/Wise 23-24/Causal Data Science for Business Analytics/Causal_Data_Science_Data/coupon.rds’) head(coupon_data)\nshipping_data &lt;- readRDS(‘E:/Master Study/TUHH/Wise 23-24/Causal Data Science for Business Analytics/Causal_Data_Science_Data/shipping.rds’) head(shipping_data)\n\n\n3 Define cut-off\nc0 &lt;- 60\n\n\n4 Density test\nrddd &lt;- rddensity(coupon_data$days_since_last, c = c0) summary(rddd)\n\n\n5 Visually check continuity at running variable\nrdd_plot &lt;- rdplotdensity(rddd, coupon_data$days_since_last, plotN = 100)\n\n\n6 Specify bandwidth\nbw &lt;- c0 + c(-30, 60)\n\n\n7 Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- coupon_data %&gt;% filter(days_since_last &gt;= bw[1] & days_since_last &lt; c0) df_bw_above &lt;- coupon_data %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw[2])\n\n\n8 Alternative way to define tables\n\n\n9 df_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw[1], days_since_last &lt; c0)\n\n\n10 df_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0, days_since_last &lt;= bw[2])\ndf_bw &lt;- bind_rows(df_bw_above, df_bw_below) dim(df_bw)\n\n\n11 Plot dependent variable vs running variable\ndep_var &lt;- ggplot(coupon_data, aes(x = days_since_last, y = purchase_after, color = coupon)) + geom_vline(xintercept = c0, color = “green”) + geom_point(alpha = 0.1, size = 0.2) + # add lines for the full range geom_smooth(data = filter(coupon_data, days_since_last &lt;= c0), method = “lm”, se = F, linewidth = 1, linetype = “dashed”) + geom_smooth(data = filter(coupon_data, days_since_last &gt; c0), method = “lm”, se = F, linewidth = 1, linetype = “dashed”) + # add lines for specified bandwidth geom_smooth(data = df_bw_below, method = “lm”, se = F, color = “green”, linewidth = 2) + geom_smooth(data = df_bw_above, method = “lm”, se = F, color = “green”, linewidth = 2) + scale_color_discrete(labels = c(“No coupon”, “Coupon”)) + xlab(“Days since last purchase”) + ylab(“Purchase after coupon assignment”) + theme(legend.title = element_blank()) dep_var\n\n\n12 [3.2] Local Average treatment effect (LATE) —-\n\n\n13 Extract values for vertical lines to visualize local average treatment effect\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below) model_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0)) y1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\nlate &lt;- y1 - y0 sprintf(“LATE: %.2f”, late)\n\n\n14 Minimum and maximum for y-axis limits\nmin_y &lt;- min(df_bw\\(purchase_after) max_y &lt;- max(df_bw\\)purchase_after)\n\n\n15 Add lines for vertical distance and change limits of x-axis.\ndep_var_bw &lt;- ggplot(df_bw, aes(x = days_since_last, y = purchase_after, color = coupon)) + geom_vline(xintercept = c0, color = “white”, linewidth = 2) + geom_point(alpha = 0.4, size = 1) + geom_smooth(data = df_bw_below, method = “lm”, se = F, linewidth = 2) + geom_smooth(data = df_bw_above, method = “lm”, se = F, linewidth = 2) + geom_segment(aes(x = c0, xend = bw[2], y = y0, yend = y0), linetype = “dotted”, color = “white”) + geom_segment(aes(x = bw[1], xend = c0, y = y1, yend = y1), linetype = “dotted”, color = “white”[4]) + annotate(“text”, x = c0+2, y = mean(c(y1, y0)-2), label = sprintf(“Difference: %.2f”, (y1 - y0)), color = “white”, fontface = 2) + scale_y_continuous(limits = c(min_y, max_y)) + scale_color_discrete(labels = c(“No coupon”, “Coupon”)) + xlab(“Days since last purchase”) + ylab(“Purchase after coupon assignment”) + theme(legend.title = element_blank()) dep_var_bw\nlm_bw &lt;- lm(purchase_after ~ days_since_last_centered + coupon, df_bw) summary(lm_bw)\n\n\n16 Using 30 EUR as a cutoff of running variable\nsummary(shipping_data$purchase_amount)\n\n\n17 Plot the distribution of purchase_amount\nggplot(shipping_data, aes(x = purchase_amount)) + geom_histogram(binwidth = 5, fill = “blue”, color = “black”) + labs(title = “Distribution of Purchase Amount”, x = “Purchase Amount (€)”, y = “Frequency”)\n:::"
  },
  {
    "objectID": "content/01_journal/01_probability.html#compute-probabilities",
    "href": "content/01_journal/01_probability.html#compute-probabilities",
    "title": "Probablity Theory",
    "section": "1.2 Compute probabilities",
    "text": "1.2 Compute probabilities\nP_T_and_S &lt;- P_S * P_T_given_S P_T_and_not_S &lt;- P_not_S * P_T_given_not_S P_not_T_and_S &lt;- P_S * P_not_T_given_S P_not_T_and_not_S &lt;- P_not_S * P_not_T_given_not_S"
  },
  {
    "objectID": "content/01_journal/01_probability.html#sum-of-all-four-probabilities",
    "href": "content/01_journal/01_probability.html#sum-of-all-four-probabilities",
    "title": "Probablity Theory",
    "section": "1.3 Sum of all four probabilities",
    "text": "1.3 Sum of all four probabilities\nsum_of_probabilities &lt;- P_T_and_S + P_T_and_not_S + P_not_T_and_S + P_not_T_and_not_S"
  },
  {
    "objectID": "content/01_journal/01_probability.html#print-the-results",
    "href": "content/01_journal/01_probability.html#print-the-results",
    "title": "Probablity Theory",
    "section": "1.4 Print the results",
    "text": "1.4 Print the results\ncat(“P(T ∩ S):”, P_T_and_S, “”) cat(“P(T ∩ ~S):”, P_T_and_not_S, “”) cat(“P(~T ∩ S):”, P_not_T_and_S, “”) cat(“P(~T ∩ ~S):”, P_not_T_and_not_S, “”) cat(“Sum of all four probabilities:”, sum_of_probabilities, “”)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#given-probabilities",
    "href": "content/01_journal/01_probability.html#given-probabilities",
    "title": "Probablity Theory",
    "section": "1.1 Given probabilities",
    "text": "1.1 Given probabilities\nP_S &lt;- 0.3 P_not_S &lt;- 0.7\nP_T_given_S &lt;- 0.2 P_not_T_given_S &lt;- 0.8\nP_T_given_not_S &lt;- 0.6 P_not_T_given_not_S &lt;- 0.4"
  },
  {
    "objectID": "content/01_journal/01_probability.html#from-diagram-venn",
    "href": "content/01_journal/01_probability.html#from-diagram-venn",
    "title": "Probablity Theory",
    "section": "2.1 From Diagram Venn",
    "text": "2.1 From Diagram Venn\nlibrary(knitr) image_url &lt;- “https://owmork.github.io/causal_ds/content/fundamentals/01_a_prob_files/figure-html/unnamed-chunk-5-1.png” include_graphics(image_url)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#replace-the-url-with-the-actual-url-of-the-image",
    "href": "content/01_journal/01_probability.html#replace-the-url-with-the-actual-url-of-the-image",
    "title": "1 Assignment 1",
    "section": "2.2 Replace the URL with the actual URL of the image",
    "text": "2.2 Replace the URL with the actual URL of the image\nimage_url &lt;- “https://owmork.github.io/causal_ds/content/fundamentals/01_a_prob_files/figure-html/unnamed-chunk-5-1.png”"
  },
  {
    "objectID": "content/01_journal/01_probability.html#include-the-image-using-knitrinclude_graphics",
    "href": "content/01_journal/01_probability.html#include-the-image-using-knitrinclude_graphics",
    "title": "1 Assignment 1",
    "section": "2.3 Include the image using knitr::include_graphics",
    "text": "2.3 Include the image using knitr::include_graphics\ninclude_graphics(image_url)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#given-data",
    "href": "content/01_journal/01_probability.html#given-data",
    "title": "Probablity Theory",
    "section": "2.2 Given data",
    "text": "2.2 Given data\nall_three_devices &lt;- 5 at_least_two_devices &lt;- 73+33+88 only_one_device &lt;- 278+423+100"
  },
  {
    "objectID": "content/01_journal/01_probability.html#calculate-percentages",
    "href": "content/01_journal/01_probability.html#calculate-percentages",
    "title": "Probablity Theory",
    "section": "2.4 Calculate percentages",
    "text": "2.4 Calculate percentages\npercentage_all_three_devices &lt;- (all_three_devices / total_customers) * 100 percentage_at_least_two_devices &lt;- (at_least_two_devices / total_customers) * 100 percentage_only_one_device &lt;- (only_one_device / total_customers) * 100"
  },
  {
    "objectID": "content/01_journal/01_probability.html#print-the-results-1",
    "href": "content/01_journal/01_probability.html#print-the-results-1",
    "title": "Probablity Theory",
    "section": "2.5 Print the results",
    "text": "2.5 Print the results\ncat(“Percentage of customers using all three devices:”, percentage_all_three_devices, “%”) cat(“Percentage of customers using at least two devices:”, percentage_at_least_two_devices, “%”) cat(“Percentage of customers using only one device:”, percentage_only_one_device, “%”)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#total-number-of-customers",
    "href": "content/01_journal/01_probability.html#total-number-of-customers",
    "title": "Probablity Theory",
    "section": "2.3 Total number of customers",
    "text": "2.3 Total number of customers\ntotal_customers &lt;- all_three_devices + at_least_two_devices + only_one_device"
  },
  {
    "objectID": "content/01_journal/01_probability.html#given-probabilities-1",
    "href": "content/01_journal/01_probability.html#given-probabilities-1",
    "title": "Probablity Theory",
    "section": "3.1 Given probabilities",
    "text": "3.1 Given probabilities\nP_Alarm_given_Faulty_prod &lt;- 0.97 P_Alarm_given_not_Faulty_prod &lt;- 0.01 P_Faulty_prod &lt;- 0.04 P_not_Faulty_prod &lt;- 1 - P_Faulty_prod"
  },
  {
    "objectID": "content/01_journal/01_probability.html#calculate-palarm",
    "href": "content/01_journal/01_probability.html#calculate-palarm",
    "title": "Probablity Theory",
    "section": "3.2 Calculate P(Alarm)",
    "text": "3.2 Calculate P(Alarm)\nP_Alarm &lt;- P_Alarm_given_Faulty_prod * P_Faulty_prod + P_Alarm_given_not_Faulty_prod * P_not_Faulty_prod"
  },
  {
    "objectID": "content/01_journal/01_probability.html#calculate-pfaulty_prod-alarm-using-bayes-theorem",
    "href": "content/01_journal/01_probability.html#calculate-pfaulty_prod-alarm-using-bayes-theorem",
    "title": "Probablity Theory",
    "section": "3.3 (1) Calculate P(~Faulty_prod | Alarm) using Bayes’ Theorem",
    "text": "3.3 (1) Calculate P(~Faulty_prod | Alarm) using Bayes’ Theorem\nP_not_Faulty_prod_given_Alarm &lt;- (P_Alarm_given_not_Faulty_prod * P_not_Faulty_prod) / P_Alarm"
  },
  {
    "objectID": "content/01_journal/01_probability.html#calculate-pfaulty_prod-alarm-using-bayes-theorem-1",
    "href": "content/01_journal/01_probability.html#calculate-pfaulty_prod-alarm-using-bayes-theorem-1",
    "title": "Probablity Theory",
    "section": "3.4 (2) Calculate P(Faulty_prod | Alarm) using Bayes’ Theorem",
    "text": "3.4 (2) Calculate P(Faulty_prod | Alarm) using Bayes’ Theorem\nP_Faulty_prod_given_Alarm &lt;- (P_Alarm_given_Faulty_prod * P_Faulty_prod) / P_Alarm"
  },
  {
    "objectID": "content/01_journal/01_probability.html#print-the-results-2",
    "href": "content/01_journal/01_probability.html#print-the-results-2",
    "title": "Probablity Theory",
    "section": "3.5 Print the results",
    "text": "3.5 Print the results\ncat(“a. P(~Faulty_prod | Alarm):”, P_not_Faulty_prod_given_Alarm, “”) cat(“b. P(Faulty_prod | Alarm):”, P_Faulty_prod_given_Alarm, “”)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#fill-in-the-gaps-in-the-sentence",
    "href": "content/01_journal/01_probability.html#fill-in-the-gaps-in-the-sentence",
    "title": "Probablity Theory",
    "section": "3.6 Fill in the gaps in the sentence",
    "text": "3.6 Fill in the gaps in the sentence\npercentage_not_Faulty_prod_given_Alarm &lt;- round(P_not_Faulty_prod_given_Alarm * 100, 2) percentage_Faulty_prod_given_Alarm &lt;- round(P_Faulty_prod_given_Alarm * 100, 2)\ncat(“These results show that in case the alarm is triggered, there is a possibility of about”, percentage_not_Faulty_prod_given_Alarm, “% that the product is flawless and a probability of”, percentage_Faulty_prod_given_Alarm, “% that the product is faulty.”, “”)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#regression-of-avg_purch-on-card-membership",
    "href": "content/01_journal/07_matching.html#regression-of-avg_purch-on-card-membership",
    "title": "Matching and Subsclassifications",
    "section": "4.1 Regression of avg_purch on card membership",
    "text": "4.1 Regression of avg_purch on card membership\nsummary(model_naive)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#subclassification-estimator-subclasses-z-0-ancard-z-1",
    "href": "content/01_journal/07_matching.html#subclassification-estimator-subclasses-z-0-ancard-z-1",
    "title": "Matching and Subclassification",
    "section": "4.2 Subclassification estimator (subclasses: Z = 0 ancard Z = 1)",
    "text": "4.2 Subclassification estimator (subclasses: Z = 0 ancard Z = 1)\n\nE(sex, card)\nE_00 &lt;- mean(membership[(membership\\(sex==0 & membership\\)card==0), ]\\(avg_purch) # control men E_10 &lt;- mean(membership[(membership\\)sex==1 & membership\\(card==0), ]\\)avg_purch) # control women E_01 &lt;- mean(membership[(membership\\(sex==0 & membership\\)card==1), ]\\(avg_purch) # treatment men E_11 &lt;- mean(membership[(membership\\)sex==1 & membership\\(card==1), ]\\)avg_purch) # treatment women"
  },
  {
    "objectID": "content/01_journal/07_matching.html#weighted-by-k-proportion-of-femalemale",
    "href": "content/01_journal/07_matching.html#weighted-by-k-proportion-of-femalemale",
    "title": "Matching and Subclassification",
    "section": "4.3 Weighted by K (proportion of female/male)",
    "text": "4.3 Weighted by K (proportion of female/male)\nK &lt;- mean(sex)\nK(E_11-E_10) + (1-K)(E_01 - E_00)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#coarsened-exact-matching-cem",
    "href": "content/01_journal/07_matching.html#coarsened-exact-matching-cem",
    "title": "Matching and Subsclassifications",
    "section": "5.1 Coarsened Exact Matching (CEM)",
    "text": "5.1 Coarsened Exact Matching (CEM)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#without-specifying-coarsening",
    "href": "content/01_journal/07_matching.html#without-specifying-coarsening",
    "title": "Matching and Subsclassifications",
    "section": "5.2 Without specifying coarsening",
    "text": "5.2 Without specifying coarsening\n\n(1) Matching\ncem &lt;- matchit(card ~ age + sex + pre_avg_purch, data = membership, method = ‘cem’, estimand = ‘ATE’)\nsummary(cem) ## Use matched data df_cem &lt;- match.data(cem)\n\n\n(2) Estimation\nmodel_cem &lt;- lm(avg_purch ~ card, data = df_cem, weights = weights) summary(model_cem)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#matching",
    "href": "content/01_journal/07_matching.html#matching",
    "title": "Matching and Subsclassifications",
    "section": "5.3 (1) Matching",
    "text": "5.3 (1) Matching\ncem &lt;- matchit(card ~ age + sex + pre_avg_purch, data = membership, method = ‘cem’, estimand = ‘ATE’)\nsummary(cem) ## Use matched data df_cem &lt;- match.data(cem)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#estimation",
    "href": "content/01_journal/07_matching.html#estimation",
    "title": "Matching and Subsclassifications",
    "section": "5.4 (2) Estimation",
    "text": "5.4 (2) Estimation\nmodel_cem &lt;- lm(avg_purch ~ card, data = df_cem, weights = weights) summary(model_cem)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#matching-1",
    "href": "content/01_journal/07_matching.html#matching-1",
    "title": "Matching and Subsclassifications",
    "section": "6.1 (1) Matching",
    "text": "6.1 (1) Matching"
  },
  {
    "objectID": "content/01_journal/07_matching.html#replace-one-to-one-or-one-to-many-matching",
    "href": "content/01_journal/07_matching.html#replace-one-to-one-or-one-to-many-matching",
    "title": "Matching and Subsclassifications",
    "section": "6.2 replace: one-to-one or one-to-many matching",
    "text": "6.2 replace: one-to-one or one-to-many matching\nnn &lt;- matchit(card ~ sex + age + pre_avg_purch, data = membership, method = “nearest”, # changed distance = “mahalanobis”, # changed replace = T)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#covariate-balance",
    "href": "content/01_journal/07_matching.html#covariate-balance",
    "title": "Matching and Subsclassifications",
    "section": "6.3 Covariate Balance",
    "text": "6.3 Covariate Balance\nsummary(nn)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#use-matched-data",
    "href": "content/01_journal/07_matching.html#use-matched-data",
    "title": "Matching and Subsclassifications",
    "section": "6.4 Use matched data",
    "text": "6.4 Use matched data\ndf_nn &lt;- match.data(nn)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#estimation-1",
    "href": "content/01_journal/07_matching.html#estimation-1",
    "title": "Matching and Subsclassifications",
    "section": "5.4 (2) Estimation",
    "text": "5.4 (2) Estimation\nmodel_nn &lt;- lm(avg_purch ~ card, data = df_nn, weights = weights) summary(model_nn)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#propensity-scores",
    "href": "content/01_journal/07_matching.html#propensity-scores",
    "title": "Matching and Subsclassifications",
    "section": "7.1 (1) Propensity scores",
    "text": "7.1 (1) Propensity scores\nmodel_prop &lt;- glm(card ~ sex + age + pre_avg_purch, data = membership, family = binomial(link = “logit”)) summary(model_prop)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#add-propensities-to-table",
    "href": "content/01_journal/07_matching.html#add-propensities-to-table",
    "title": "Matching and Subsclassifications",
    "section": "7.2 Add propensities to table",
    "text": "7.2 Add propensities to table\nmembership_aug &lt;- membership %&gt;% mutate(propensity = predict(model_prop, type = “response”))\n##Extend data by IPW scores membership_ipw &lt;- membership_aug %&gt;% mutate( ipw = (card/propensity) + ((1-card) / (1-propensity)))"
  },
  {
    "objectID": "content/01_journal/07_matching.html#look-at-data-with-ipw-scores",
    "href": "content/01_journal/07_matching.html#look-at-data-with-ipw-scores",
    "title": "Matching and Subsclassifications",
    "section": "7.3 Look at data with IPW scores",
    "text": "7.3 Look at data with IPW scores\nmembership_ipw %&gt;% select(card, sex, age, pre_avg_purch, propensity, ipw)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#estimation-2",
    "href": "content/01_journal/07_matching.html#estimation-2",
    "title": "Matching and Subsclassifications",
    "section": "5.6 (2) Estimation",
    "text": "5.6 (2) Estimation\nmodel_ipw &lt;- lm(avg_purch ~ card, data = membership_ipw, weights = ipw) summary(model_ipw)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#plot-histogram-of-estimated-propensities",
    "href": "content/01_journal/07_matching.html#plot-histogram-of-estimated-propensities",
    "title": "Matching and Subsclassifications",
    "section": "7.5 Plot histogram of estimated propensities",
    "text": "7.5 Plot histogram of estimated propensities\nggplot(membership_aug, aes(x = propensity)) + geom_histogram(alpha = .8, color = “white”)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#looking-for-observations-with-highest-weights",
    "href": "content/01_journal/07_matching.html#looking-for-observations-with-highest-weights",
    "title": "Matching and Subsclassifications",
    "section": "6.1 Looking for observations with highest weights",
    "text": "6.1 Looking for observations with highest weights\nmembership_ipw %&gt;% dplyr::select(card, sex, age, pre_avg_purch, propensity, ipw) %&gt;% arrange(desc(ipw))"
  },
  {
    "objectID": "content/01_journal/07_matching.html#run-with-high-weights-excluded",
    "href": "content/01_journal/07_matching.html#run-with-high-weights-excluded",
    "title": "Matching and Subsclassifications",
    "section": "6.2 Run with high weights excluded",
    "text": "6.2 Run with high weights excluded\nmodel_ipw_trim &lt;- lm(avg_purch ~ card, data = membership_ipw %&gt;% filter(propensity %&gt;% between(0.15, 0.85)), weights = ipw) summary(model_ipw_trim)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#regression-of-avg_purch-on-card-membership",
    "href": "content/01_journal/09_iv.html#regression-of-avg_purch-on-card-membership",
    "title": "Instrumental Variables",
    "section": "3.1 Regression of avg_purch on card membership",
    "text": "3.1 Regression of avg_purch on card membership\nsummary(naive_estimate)\nnaive_estimate &lt;- lm(time_spent ~ rand_enc + used_ftr, data = rand_enc) summary(naive_estimate)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#first-stage",
    "href": "content/01_journal/09_iv.html#first-stage",
    "title": "Instrumental Variables",
    "section": "5.1 First stage",
    "text": "5.1 First stage\nfirst_stage &lt;- lm(used_ftr ~ rand_enc, data = rand_enc) summary(first_stage)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#predicted-probabilities-from-first-stage",
    "href": "content/01_journal/09_iv.html#predicted-probabilities-from-first-stage",
    "title": "Instrumental Variables",
    "section": "5.2 Predicted ‘probabilities’ from first stage",
    "text": "5.2 Predicted ‘probabilities’ from first stage\npred_fs &lt;- predict(first_stage)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#create-table-with-predictions-and-actual-decisions",
    "href": "content/01_journal/09_iv.html#create-table-with-predictions-and-actual-decisions",
    "title": "Instrumental Variables",
    "section": "5.3 Create table with predictions and actual decisions",
    "text": "5.3 Create table with predictions and actual decisions\npred_vs_actl &lt;- tibble( pred = pred_fs, actl = rand_enc$used_ftr )"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#calculation",
    "href": "content/01_journal/02_statistics.html#calculation",
    "title": "Statistical Concepts",
    "section": "1.1 Calculation",
    "text": "1.1 Calculation\nexpected_age &lt;- mean(random_vars\\(age) expected_income &lt;- mean(random_vars\\)income) variance_age &lt;- var(random_vars\\(age) variance_income &lt;- var(random_vars\\)income) sd_age &lt;- sd(random_vars\\(age) sd_income &lt;- sd(random_vars\\)income)"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#print-result",
    "href": "content/01_journal/02_statistics.html#print-result",
    "title": "Statistical Concepts",
    "section": "1.2 Print result",
    "text": "1.2 Print result\ncat(“Mean age :”, expected_age, “”) cat(“Mean income :”, expected_income, “”) cat(“Variance of age:”, variance_age, “”) cat(“Variance of income:”, variance_income, “”) cat(“Standard deviation of age:”, sd_age, “”) cat(“Standard deviation of income:”, sd_income, “”)"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#print-result-1",
    "href": "content/01_journal/02_statistics.html#print-result-1",
    "title": "Statistical Concepts",
    "section": "3.2 Print Result",
    "text": "3.2 Print Result\ncat(“Covariance :”, covariance, “”) cat(“Correlation :”, correlation, “”)"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#calculate-mean-for-age-18",
    "href": "content/01_journal/02_statistics.html#calculate-mean-for-age-18",
    "title": "Statistical Concepts",
    "section": "4.1 Calculate mean for age <= 18",
    "text": "4.1 Calculate mean for age &lt;= 18\nmean_age_under_18 &lt;- mean(random_vars\\(age[random_vars\\)age &lt;= 18]) mean_age_between_1865 &lt;- mean(random_vars\\(age[random_vars\\)age &gt;= 18 & random_vars\\(age &lt;= 65]) mean_age_above_65 &lt;- mean(random_vars\\)age[random_vars$age &gt;= 65])"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#print-the-result",
    "href": "content/01_journal/02_statistics.html#print-the-result",
    "title": "Statistical Concepts",
    "section": "5.2 Print the result",
    "text": "5.2 Print the result\ncat(“Mean income for age &lt;= 18:”, mean_age_under_18, “”) cat(“Mean income for 18&lt;age&lt;65:”, mean_age_between_1865, “”) cat(“Mean income for age &gt;= 65:”, mean_age_above_65, “”)"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#calculation-1",
    "href": "content/01_journal/02_statistics.html#calculation-1",
    "title": "Statistical Concepts",
    "section": "3.1 Calculation",
    "text": "3.1 Calculation\ncovariance &lt;- cov(random_vars\\(age, random_vars\\)income) correlation &lt;- cor(random_vars\\(age, random_vars\\)income)"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#calculation-2",
    "href": "content/01_journal/02_statistics.html#calculation-2",
    "title": "Statistical Concepts",
    "section": "5.1 Calculation",
    "text": "5.1 Calculation\nmean_age_under_18 &lt;- mean(random_vars\\(age[random_vars\\)age &lt;= 18]) mean_age_between_1865 &lt;- mean(random_vars\\(age[random_vars\\)age &gt;= 18 & random_vars\\(age &lt;= 65]) mean_age_above_65 &lt;- mean(random_vars\\)age[random_vars$age &gt;= 65])"
  },
  {
    "objectID": "content/01_journal/03_regression.html#include-all-potential-regressors",
    "href": "content/01_journal/03_regression.html#include-all-potential-regressors",
    "title": "Regression and Statistical Inference",
    "section": "4.1 Include all potential regressors",
    "text": "4.1 Include all potential regressors\nlm_all &lt;- lm(price ~ ., data = car_prices) summary(lm_all)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#naive-comparison",
    "href": "content/01_journal/07_matching.html#naive-comparison",
    "title": "Matching and Subsclassifications",
    "section": "4.1 Naive comparison",
    "text": "4.1 Naive comparison\nE_0 &lt;- mean(membership[membership\\(card==0, ]\\)avg_purch) # control group E_1 &lt;- mean(membership[membership\\(card==1, ]\\)avg_purch) # treatment group E_1 - E_0 model_naive &lt;- lm(avg_purch ~ card, membership) summary(model_naive)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#nearest-neighbor-matching-nnm",
    "href": "content/01_journal/07_matching.html#nearest-neighbor-matching-nnm",
    "title": "Matching and Subsclassifications",
    "section": "5.3 Nearest-Neighbor Matching (NNM)",
    "text": "5.3 Nearest-Neighbor Matching (NNM)\n\n(1) Matching\n\nreplace: one-to-one or one-to-many matching\nnn &lt;- matchit(card ~ sex + age + pre_avg_purch, data = membership, method = “nearest”, # changed distance = “mahalanobis”, # changed replace = T)\n\n\nCovariate Balance\nsummary(nn)\n\n\nUse matched data\ndf_nn &lt;- match.data(nn)\n\n\n\n(2) Estimation\nmodel_nn &lt;- lm(avg_purch ~ card, data = df_nn, weights = weights) summary(model_nn)"
  },
  {
    "objectID": "content/01_journal/07_matching.html#inverse-probability-weighting-ipw",
    "href": "content/01_journal/07_matching.html#inverse-probability-weighting-ipw",
    "title": "Matching and Subsclassifications",
    "section": "5.4 Inverse Probability Weighting (IPW)",
    "text": "5.4 Inverse Probability Weighting (IPW)\n\n(1) Propensity scores\nmodel_prop &lt;- glm(card ~ sex + age + pre_avg_purch, data = membership, family = binomial(link = “logit”)) summary(model_prop)\n\nAdd propensities to table\nmembership_aug &lt;- membership %&gt;% mutate(propensity = predict(model_prop, type = “response”))\n\n\nExtend data by IPW scores\nmembership_ipw &lt;- membership_aug %&gt;% mutate( ipw = (card/propensity) + ((1-card) / (1-propensity)))\n\n\nLook at data with IPW scores\nmembership_ipw %&gt;% select(card, sex, age, pre_avg_purch, propensity, ipw)\n\n\n\n(2) Estimation\nmodel_ipw &lt;- lm(avg_purch ~ card, data = membership_ipw, weights = ipw) summary(model_ipw)\n\nPlot histogram of estimated propensities\nggplot(membership_aug, aes(x = propensity)) + geom_histogram(alpha = .8, color = “white”)\n\n\nLooking for observations with highest weights\nmembership_ipw %&gt;% dplyr::select(card, sex, age, pre_avg_purch, propensity, ipw) %&gt;% arrange(desc(ipw))\n\n\nRun with high weights excluded\nmodel_ipw_trim &lt;- lm(avg_purch ~ card, data = membership_ipw %&gt;% filter(propensity %&gt;% between(0.15, 0.85)), weights = ipw) summary(model_ipw_trim)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#naive-comparison",
    "href": "content/01_journal/09_iv.html#naive-comparison",
    "title": "Instrumental Variables",
    "section": "4.1 Naive comparison",
    "text": "4.1 Naive comparison\nE_0 &lt;- mean(rand_enc[rand_enc\\(rand_enc==0, ]\\)time_spent) # control group E_1 &lt;- mean(rand_enc[rand_enc\\(rand_enc==1, ]\\)time_spent) # treatment group E_1 - E_0 naive_estimate &lt;- lm(used_ftr ~ time_spent, data = rand_enc)\n\nRegression of avg_purch on card membership\nsummary(naive_estimate)\nnaive_estimate &lt;- lm(time_spent ~ rand_enc + used_ftr, data = rand_enc) summary(naive_estimate)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#instrumental-variable-estimation-2sls",
    "href": "content/01_journal/09_iv.html#instrumental-variable-estimation-2sls",
    "title": "Instrumental Variables",
    "section": "6.1 Instrumental Variable Estimation (2SLS)",
    "text": "6.1 Instrumental Variable Estimation (2SLS)\n\nFirst stage\nfirst_stage &lt;- lm(used_ftr ~ rand_enc, data = rand_enc) summary(first_stage)\n\nPredicted ‘probabilities’ from first stage\npred_fs &lt;- predict(first_stage)\n\n\nCreate table with predictions and actual decisions\npred_vs_actl &lt;- tibble( pred = pred_fs, actl = rand_enc$used_ftr )\n\n\nPlot predictions vs original\nggplot(pred_vs_actl, aes(x = pred, y = actl, color = as.factor(actl))) + geom_jitter(alpha = .5) + scale_color_discrete(labels = c(“Control Group”, “Treatment Group”)) + theme(legend.title = element_blank())\n\n\n\nSecond stage\nsecond_stage &lt;- lm(rand_enc\\(time_spent ~ first_stage\\)fitted.values) summary(second_stage)\n\n\nIV Estimate\niv_estimate &lt;- iv_robust(time_spent ~ used_ftr | rand_enc, data = rand_enc) summary(iv_estimate)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#compare-naive-and-iv-estimates",
    "href": "content/01_journal/09_iv.html#compare-naive-and-iv-estimates",
    "title": "Instrumental Variables",
    "section": "6.2 Compare naive and IV estimates",
    "text": "6.2 Compare naive and IV estimates\nsummary(naive_estimate) summary(iv_estimate)\nprint(“In this case, naive estimation is considered bias based on two reasons. First, the result of time spent isn’t just single factor based on new feature used. And this is proved by the second reason, in which R-squared has low value.”) print(“Naive estimate has a downward bias, by comparing its intercept value versus the difference between control and treatment group”)"
  }
]